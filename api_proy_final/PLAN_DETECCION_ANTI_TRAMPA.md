# üéì Sistema de Detecci√≥n Anti-Trampa para Ex√°menes
# Implementaci√≥n con ESP32-CAM + Python + YOLO

## üìã Arquitectura Propuesta

```
ESP32-CAM (Captura) 
    ‚Üì HTTP POST cada 5 segundos
Python Server (Detecci√≥n YOLO)
    ‚Üì Guarda imagen + metadata
Node.js Backend (Almacenamiento)
    ‚Üì WebSocket
Dashboard React (Alertas en tiempo real)
```

---

## üîß Componentes a Implementar

### 1. ESP32-CAM: Captura Autom√°tica
**Archivo:** `ESP32CAM_ModoExamen.ino`

**Funcionalidad:**
- Captura foto cada 5 segundos
- Env√≠a a servidor Python v√≠a HTTP POST
- Incluye timestamp y ID del estudiante

**C√≥digo a agregar:**
```cpp
// En loop()
void loop() {
  static unsigned long lastCapture = 0;
  unsigned long now = millis();
  
  if (now - lastCapture > 5000) {  // Cada 5 segundos
    captureAndSend();
    lastCapture = now;
  }
}

void captureAndSend() {
  camera_fb_t *fb = esp_camera_fb_get();
  if (!fb) return;
  
  // Enviar a Python server
  HTTPClient http;
  http.begin("http://TU_SERVIDOR_PYTHON:5001/detect_exam");
  http.addHeader("Content-Type", "image/jpeg");
  
  int httpCode = http.POST(fb->buf, fb->len);
  
  esp_camera_fb_return(fb);
  http.end();
}
```

---

### 2. Python Server: Detecci√≥n con YOLO
**Archivo:** `server_detection.py`

**Dependencias a agregar en `requirements.txt`:**
```
flask
opencv-python
ultralytics  # YOLOv8
pillow
numpy
google-cloud-storage  # Para guardar en Cloud Storage
```

**Funcionalidad:**
- Recibe imagen de ESP32-CAM
- Detecta objetos con YOLOv8
- Identifica:
  - üì± Celulares (class: cell phone)
  - üë• Personas (class: person) - debe ser solo 1
  - üìñ Libros (class: book)
  - üíª Laptops (class: laptop)
- Guarda imagen si hay detecci√≥n sospechosa
- Env√≠a alerta a Node.js backend

**C√≥digo base:**
```python
from flask import Flask, request, jsonify
from ultralytics import YOLO
import cv2
import numpy as np
from datetime import datetime
import os
import requests

app = Flask(__name__)

# Cargar modelo YOLO
model = YOLO('yolov8n.pt')  # Modelo nano (r√°pido)

# Objetos sospechosos
SUSPICIOUS_CLASSES = ['cell phone', 'book', 'laptop']
IMAGES_DIR = "exam_captures"
os.makedirs(IMAGES_DIR, exist_ok=True)

NODE_BACKEND = "https://api-tresa.onrender.com/api/exam-alerts"

@app.route('/detect_exam', methods=['POST'])
def detect_exam():
    try:
        # Recibir imagen
        img_bytes = request.data
        nparr = np.frombuffer(img_bytes, np.uint8)
        img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        
        # Detectar objetos
        results = model(img)
        
        # Analizar detecciones
        detections = []
        is_suspicious = False
        person_count = 0
        
        for r in results:
            for box in r.boxes:
                class_name = model.names[int(box.cls)]
                confidence = float(box.conf)
                
                if class_name == 'person':
                    person_count += 1
                
                if class_name in SUSPICIOUS_CLASSES and confidence > 0.5:
                    is_suspicious = True
                    detections.append({
                        'object': class_name,
                        'confidence': confidence
                    })
        
        # Verificar n√∫mero de personas
        if person_count != 1:
            is_suspicious = True
            detections.append({
                'object': 'multiple_persons' if person_count > 1 else 'no_person',
                'confidence': 1.0
            })
        
        # Guardar imagen si es sospechosa
        if is_suspicious:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"suspicious_{timestamp}.jpg"
            filepath = os.path.join(IMAGES_DIR, filename)
            
            # Dibujar detecciones en la imagen
            annotated = results[0].plot()
            cv2.imwrite(filepath, annotated)
            
            # Enviar alerta al backend
            alert_data = {
                'timestamp': timestamp,
                'image_url': f'/exam_images/{filename}',
                'detections': detections,
                'severity': 'high' if len(detections) > 1 else 'medium'
            }
            
            try:
                requests.post(NODE_BACKEND, json=alert_data)
            except Exception as e:
                print(f"Error enviando alerta: {e}")
            
            return jsonify({
                'status': 'suspicious',
                'detections': detections,
                'image_saved': filename
            }), 200
        
        return jsonify({
            'status': 'ok',
            'person_count': person_count
        }), 200
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/exam_images/<filename>')
def serve_image(filename):
    return send_from_directory(IMAGES_DIR, filename)

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5001)
```

---

### 3. Node.js Backend: Endpoint de Alertas
**Archivo:** `server.js` (agregar endpoint)

```javascript
// Endpoint para recibir alertas de examen
app.post('/api/exam-alerts', async (req, res) => {
  try {
    const { timestamp, image_url, detections, severity } = req.body;
    
    // Guardar en base de datos
    const alert = await ExamAlert.create({
      timestamp: new Date(timestamp),
      imageUrl: image_url,
      detections: JSON.stringify(detections),
      severity: severity,
      reviewed: false
    });
    
    // Emitir evento WebSocket para alerta en tiempo real
    io.emit('exam_alert', {
      id: alert.id,
      timestamp: alert.timestamp,
      detections: detections,
      severity: severity
    });
    
    res.json({ status: 'alert_received' });
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});
```

---

### 4. Dashboard React: Panel de Alertas
**Componente:** `ExamMonitor.tsx`

```tsx
import { useEffect, useState } from 'react';
import io from 'socket.io-client';

interface ExamAlert {
  id: string;
  timestamp: Date;
  detections: Array<{object: string, confidence: number}>;
  severity: 'high' | 'medium' | 'low';
  imageUrl: string;
}

export function ExamMonitor() {
  const [alerts, setAlerts] = useState<ExamAlert[]>([]);
  
  useEffect(() => {
    const socket = io('https://api-tresa.onrender.com');
    
    socket.on('exam_alert', (alert: ExamAlert) => {
      setAlerts(prev => [alert, ...prev]);
      
      // Notificaci√≥n del navegador
      if (alert.severity === 'high') {
        new Notification('‚ö†Ô∏è Alerta de Examen', {
          body: `Detecci√≥n sospechosa: ${alert.detections.map(d => d.object).join(', ')}`,
          icon: '/alert-icon.png'
        });
      }
    });
    
    return () => socket.disconnect();
  }, []);
  
  return (
    <div className="exam-monitor">
      <h2>Monitor de Examen en Tiempo Real</h2>
      
      {alerts.map(alert => (
        <div key={alert.id} className={`alert alert-${alert.severity}`}>
          <img src={alert.imageUrl} alt="Captura" />
          <div>
            <strong>{new Date(alert.timestamp).toLocaleString()}</strong>
            <ul>
              {alert.detections.map((d, i) => (
                <li key={i}>
                  {d.object} ({(d.confidence * 100).toFixed(1)}%)
                </li>
              ))}
            </ul>
          </div>
        </div>
      ))}
    </div>
  );
}
```

---

## üéØ Objetos que YOLO Puede Detectar

### Clases √ötiles para Anti-Trampa:
- ‚úÖ `cell phone` - Celulares
- ‚úÖ `book` - Libros/apuntes
- ‚úÖ `laptop` - Computadoras
- ‚úÖ `person` - Personas (contar cu√°ntas hay)
- ‚úÖ `tv` - Pantallas adicionales
- ‚úÖ `keyboard` - Teclados externos
- ‚úÖ `mouse` - Mouse

### Reglas de Detecci√≥n:
1. **Debe haber exactamente 1 persona** ‚Üí Si hay 0 o >1, alerta
2. **No debe haber celulares** ‚Üí Alerta inmediata
3. **No debe haber libros** (si es examen cerrado)
4. **No debe haber laptops** (si es examen en papel)

---

## üìä Flujo Completo

```
1. ESP32-CAM captura foto cada 5 seg
2. Env√≠a a Python /detect_exam
3. YOLO analiza la imagen
4. Si detecta algo sospechoso:
   a. Guarda imagen con anotaciones
   b. Env√≠a alerta a Node.js
   c. Node.js emite WebSocket
   d. Dashboard muestra alerta en tiempo real
   e. Notificaci√≥n al profesor
5. Si todo est√° OK, descarta la imagen
```

---

## üíæ Almacenamiento

### Opci√≥n A: Local (Desarrollo)
```python
IMAGES_DIR = "exam_captures"
```

### Opci√≥n B: Google Cloud Storage (Producci√≥n)
```python
from google.cloud import storage

def upload_to_gcs(filepath, filename):
    client = storage.Client()
    bucket = client.bucket('exam-monitoring')
    blob = bucket.blob(f'suspicious/{filename}')
    blob.upload_from_filename(filepath)
    return blob.public_url
```

---

## üöÄ Pasos de Implementaci√≥n

### Fase 1: Setup B√°sico
1. ‚úÖ Instalar dependencias YOLO
2. ‚úÖ Descargar modelo YOLOv8
3. ‚úÖ Crear endpoint `/detect_exam`
4. ‚úÖ Probar con imagen de prueba

### Fase 2: Integraci√≥n ESP32
1. ‚úÖ Modificar ESP32 para captura peri√≥dica
2. ‚úÖ Implementar POST a servidor Python
3. ‚úÖ Probar flujo completo

### Fase 3: Backend y Frontend
1. ‚úÖ Crear modelo ExamAlert en Node.js
2. ‚úÖ Implementar WebSocket
3. ‚úÖ Crear componente ExamMonitor
4. ‚úÖ Agregar notificaciones

### Fase 4: Optimizaci√≥n
1. ‚úÖ Ajustar intervalos de captura
2. ‚úÖ Optimizar modelo YOLO
3. ‚úÖ Implementar almacenamiento en cloud
4. ‚úÖ Agregar dashboard de estad√≠sticas

---

## üìà Mejoras Futuras

1. **Detecci√≥n de mirada** ‚Üí OpenCV + Face landmarks
2. **An√°lisis de audio** ‚Üí Detectar conversaciones
3. **Detecci√≥n de movimiento** ‚Üí Alertar si sale del encuadre
4. **Reconocimiento facial** ‚Üí Verificar identidad del estudiante
5. **An√°lisis de comportamiento** ‚Üí ML para patrones sospechosos

---

## üîí Consideraciones de Privacidad

‚ö†Ô∏è **IMPORTANTE:**
- Informar a estudiantes sobre monitoreo
- Cumplir con GDPR/leyes locales
- Guardar im√°genes solo el tiempo necesario
- Encriptar almacenamiento
- Permitir revisi√≥n de falsas alarmas

---

## üí∞ Costos Estimados

### Opci√≥n 1: YOLOv8 Local
- **Servidor:** $5-10/mes (VPS b√°sico)
- **Almacenamiento:** $0.02/GB
- **Total:** ~$10/mes

### Opci√≥n 2: Google Cloud Vision API
- **API Calls:** $1.50 por 1000 im√°genes
- **Storage:** $0.02/GB
- **Total:** Variable seg√∫n uso

**Recomendaci√≥n:** Empezar con YOLO local

---

## üéì Recursos de Aprendizaje

- [YOLOv8 Docs](https://docs.ultralytics.com/)
- [ESP32-CAM HTTP POST](https://randomnerdtutorials.com/esp32-cam-post-image-photo-server/)
- [Object Detection Tutorial](https://www.youtube.com/watch?v=tFNJGim3FXw)

